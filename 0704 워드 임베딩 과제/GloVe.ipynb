{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "GloVe(Global Vectors for Word Representation)\n",
        "*   단어 임베딩을 생성하는 방법 중 하나\n",
        "* GloVe는 통계적인 기법과 동시 등장 행렬(Co-occurrence Matrix)을 활용하여 단어 간의 의미적 관련성을 파악하고, 단어 벡터를 학습함\n",
        "\n",
        "GloVe의 작동 원리\n",
        "- 동시 등장 행렬 생성\n",
        "    -  GloVe는 먼저 대규모 말뭉치(corpus)를 통해 동시 등장 행렬(co-occurrence matrix)을 생성함\n",
        "    - 동시 등장 행렬은 문맥에서 두 단어가 함께 등장한 횟수를 담고 있는 행렬\n",
        "    - 이 행렬은 단어 간의 관련성을 나타내는 정보를 제공함\n",
        "\n",
        "- 손실 함수 정의\n",
        "    - GloVe는 동시 등장 행렬을 기반으로 손실 함수(loss function)를 정의함\n",
        "    - 이 손실 함수는 단어 벡터 간의 내적 관계를 반영하도록 설계됨\n",
        "    - 즉, 비슷한 의미를 가진 단어는 벡터 공간에서 가깝게 배치되도록 학습하는 것을 목표로 함\n",
        "\n",
        "- 임베딩 벡터 학습\n",
        "    - 손실 함수를 최소화하는 방향으로 단어 벡터를 학습함\n",
        "    - 이를 위해 경사 하강법(gradient descent)이 일반적으로 사용됨\n",
        "    - 학습을 통해 단어 벡터들은 각각의 단어의 의미와 관련성을 나타내는 공간 상의 좌표로 변환됨\n",
        "\n",
        "- 단어 임베딩 활용:\n",
        "    - 학습된 단어 임베딩은 단어를 고정 길이의 벡터로 표현하여 컴퓨터가 처리하기 쉽도록 함\n",
        "    - 예) 단어 간 유사도 계산, 문장 분류, 기계 번역 등 다양한 자연어 처리 작업에서 GloVe 임베딩은 많이 사용됨\n",
        "\n",
        "> GloVe는 단어의 의미와 관련성을 벡터 공간에 투영하여 단어 간 유사도를 파악할 수 있게 함\n",
        "\n",
        "> 이를 통해 단어의 의미를 효과적으로 표현하고 자연어 처리 과제에 활용할 수 있음"
      ],
      "metadata": {
        "id": "SGKS2UcQ-dwS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Maj7mRs-el2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}